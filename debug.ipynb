{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ut_model import *\n",
    "from data_pipeline import input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/media/akanyaani/Disk2/git_repo/test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = input_fn(batch_size=16)\n",
    "\n",
    "#train_dataset = np.random.randint(low=0,high=30000,size=(10,32, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[30138    12    53  1653 15501     2 30139     0]\n",
      " [30138    49    10  2360     2 30139     0     0]\n",
      " [30138  9990    12 10816 29991     2 30139     0]\n",
      " [30138    72     7     5   642    28 30139     0]\n",
      " [30138   372    32    17   204 15506    28 30139]\n",
      " [30138   969     3  1131     2 30139     0     0]\n",
      " [30138   333     2 30139     0     0     0     0]\n",
      " [30138   195     4   175   280     2 30139     0]\n",
      " [30138    86     9  6627   229     2 30139     0]\n",
      " [30138    31   179     2 30139     0     0     0]\n",
      " [30138  5357 29927   196     2 30139     0     0]\n",
      " [30138  5444  5505     2 30139     0     0     0]\n",
      " [30138    69    97   151 30139     0     0     0]\n",
      " [30138  4699    21 20658     2 30139     0     0]\n",
      " [30138    69    97   151 30139     0     0     0]\n",
      " [30138    69    84    63   248     2 30139     0]], shape=(16, 8), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[28543    36  8133   849     2 28544     0     0]\n",
      " [28543    17    20     7  1221     2 28544     0]\n",
      " [28543  2512    20    36   849     2 28544     0]\n",
      " [28543    18    27   143   257    33 28544     0]\n",
      " [28543    27    22   105  8473    33 28544     0]\n",
      " [28543   130     8    12   578     2 28544     0]\n",
      " [28543   146    48     2 28544     0     0     0]\n",
      " [28543    14   123   190   269     2 28544     0]\n",
      " [28543    17    20     7   740   225     2 28544]\n",
      " [28543   146    15    65   338     2 28544     0]\n",
      " [28543  2249     2 28544     0     0     0     0]\n",
      " [28543    11   413    96  4656     2 28544     0]\n",
      " [28543    94   128   177 28544     0     0     0]\n",
      " [28543   186     8    12   125 13481     2 28544]\n",
      " [28543    94   128   177 28544     0     0     0]\n",
      " [28543    94   113    89   403     2 28544     0]], shape=(16, 8), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_dataset:\n",
    "    print(i)\n",
    "    print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_input = j[:, :-1]\n",
    "target_output = j[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 7), dtype=int64, numpy=\n",
       "array([[28543,    36,  8133,   849,     2, 28544,     0],\n",
       "       [28543,    17,    20,     7,  1221,     2, 28544],\n",
       "       [28543,  2512,    20,    36,   849,     2, 28544],\n",
       "       [28543,    18,    27,   143,   257,    33, 28544],\n",
       "       [28543,    27,    22,   105,  8473,    33, 28544],\n",
       "       [28543,   130,     8,    12,   578,     2, 28544],\n",
       "       [28543,   146,    48,     2, 28544,     0,     0],\n",
       "       [28543,    14,   123,   190,   269,     2, 28544],\n",
       "       [28543,    17,    20,     7,   740,   225,     2],\n",
       "       [28543,   146,    15,    65,   338,     2, 28544],\n",
       "       [28543,  2249,     2, 28544,     0,     0,     0],\n",
       "       [28543,    11,   413,    96,  4656,     2, 28544],\n",
       "       [28543,    94,   128,   177, 28544,     0,     0],\n",
       "       [28543,   186,     8,    12,   125, 13481,     2],\n",
       "       [28543,    94,   128,   177, 28544,     0,     0],\n",
       "       [28543,    94,   113,    89,   403,     2, 28544]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(16, 7), dtype=int64, numpy=\n",
       "array([[   36,  8133,   849,     2, 28544,     0,     0],\n",
       "       [   17,    20,     7,  1221,     2, 28544,     0],\n",
       "       [ 2512,    20,    36,   849,     2, 28544,     0],\n",
       "       [   18,    27,   143,   257,    33, 28544,     0],\n",
       "       [   27,    22,   105,  8473,    33, 28544,     0],\n",
       "       [  130,     8,    12,   578,     2, 28544,     0],\n",
       "       [  146,    48,     2, 28544,     0,     0,     0],\n",
       "       [   14,   123,   190,   269,     2, 28544,     0],\n",
       "       [   17,    20,     7,   740,   225,     2, 28544],\n",
       "       [  146,    15,    65,   338,     2, 28544,     0],\n",
       "       [ 2249,     2, 28544,     0,     0,     0,     0],\n",
       "       [   11,   413,    96,  4656,     2, 28544,     0],\n",
       "       [   94,   128,   177, 28544,     0,     0,     0],\n",
       "       [  186,     8,    12,   125, 13481,     2, 28544],\n",
       "       [   94,   128,   177, 28544,     0,     0,     0],\n",
       "       [   94,   113,    89,   403,     2, 28544,     0]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UTModel(4,\n",
    "                128,\n",
    "                4,\n",
    "                512,\n",
    "                32,\n",
    "                optimizer=\"adam\",\n",
    "                learning_rate=3e-5)\n",
    "\n",
    "model.mirrored_strategy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model from scratch..........\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.ops.summary_ops_v2.ResourceSummaryWriter at 0x7fe2745a4390>,\n",
       " <tensorflow.python.ops.summary_ops_v2.ResourceSummaryWriter at 0x7fe2f7153390>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.create_optimizer()\n",
    "model.create_checkpoint_manager(data_dir)\n",
    "model.create_summary_writer(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.983512, shape=(), dtype=float32)\n",
      "Step 0 Train_Loss 8.9835 Train_Accuracy 0.3077\n",
      "Saving checkpoint for step 0 at /media/akanyaani/Disk2/git_repo/test_data/ckpt-3\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.89116, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.9387245, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.939931, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.939128, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.9837, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.9168215, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.880385, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.887144, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.898237, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.970045, shape=(), dtype=float32)\n",
      "Step 10 Train_Loss 8.9700 Train_Accuracy 0.2909\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.759323, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.85766, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.85456, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.872988, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.883829, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 8)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 8, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n",
      "Mini Batch Loss :-  tf.Tensor(8.804529, shape=(), dtype=float32)\n",
      "(16, 8)\n",
      "(16, 7)\n",
      "Final encoder embedding :-  (16, 8, 128)\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "Executing time\n",
      "\n",
      "Final Decoder embedding :-  (16, 7, 128)\n",
      "Executing Decoder Call...............\n",
      "Executing time\n",
      "Decoder MHA1 shape (16, 7, 128)\n",
      "Decoder enc_output shape (16, 8, 128)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] mismatch In[1] shape: 8 vs. 7: [16,4,8,8] [16,4,7,32] 0 0 [Op:BatchMatMulV2] name: ut_model/decoder/encoder_0/decoder_layer/multi_head_attention_2/MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-533c745734f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/ut_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    217\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \t\t\t\t\tprint('Step {} Train_Loss {:.4f} Train_Accuracy {:.4f}'.format(\n",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/ut_model.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inputs, targets, grad_clip, clip_value)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/ut_model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input, target_input, training)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# print(\"Encoder shape :- \", enc_out.numpy().shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mdec_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/ut_model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, mask)\u001b[0m\n\u001b[1;32m    396\u001b[0m                                                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                                         \u001b[0;31m# print(\"Output shape :----- \", out.numpy().shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/layers/decoder_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_output, training, mask, padding_mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \t\tout2 = self.mha2(enc_output, enc_output, out1, mask=padding_mask,\n\u001b[0;32m---> 39\u001b[0;31m \t\t                 training=training)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"residual_conn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/layers/attention_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, mask, training)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mscaled_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultihead_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mconcat_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/akanyaani/Disk2/git_repo/universal-transformer-tensorflow2.0/layers/attention_layer.py\u001b[0m in \u001b[0;36mmultihead_attention\u001b[0;34m(self, q, k, v, training, mask)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"attn_dropout\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (..., seq_len_q, depth_v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2758\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m       return gen_math_ops.batch_mat_mul_v2(\n\u001b[0;32m-> 2760\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madj_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 8 vs. 7: [16,4,8,8] [16,4,7,32] 0 0 [Op:BatchMatMulV2] name: ut_model/decoder/encoder_0/decoder_layer/multi_head_attention_2/MatMul/"
     ]
    }
   ],
   "source": [
    "model.fit([train_dataset, train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1]], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tile(a, [32, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
